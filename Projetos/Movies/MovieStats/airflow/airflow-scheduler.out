[[34m2024-10-04 23:31:55,271[0m] {[34mscheduler_job.py:[0m696} INFO[0m - Starting the scheduler[0m
[[34m2024-10-04 23:31:55,272[0m] {[34mscheduler_job.py:[0m701} INFO[0m - Processing each file at most -1 times[0m
[[34m2024-10-04 23:31:55,279[0m] {[34mexecutor_loader.py:[0m105} INFO[0m - Loaded executor: SequentialExecutor[0m
[[34m2024-10-04 23:31:55,291[0m] {[34mmanager.py:[0m160} INFO[0m - Launched DagFileProcessorManager with pid: 96123[0m
[[34m2024-10-04 23:31:55,294[0m] {[34mscheduler_job.py:[0m1221} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-10-04 23:31:55,305[0m] {[34msettings.py:[0m55} INFO[0m - Configured default timezone Timezone('UTC')[0m
[2024-10-04 23:31:55,336] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2024-10-04 23:36:56,925[0m] {[34mscheduler_job.py:[0m1221} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-10-04 23:41:56,959[0m] {[34mscheduler_job.py:[0m1221} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-10-04 23:46:58,031[0m] {[34mscheduler_job.py:[0m1221} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-10-04 23:46:58,036[0m] {[34mscheduler_job.py:[0m1244} INFO[0m - Marked 1 SchedulerJob instances as failed[0m
[[34m2024-10-04 23:52:00,732[0m] {[34mscheduler_job.py:[0m1221} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-10-04 23:57:00,919[0m] {[34mscheduler_job.py:[0m1221} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-10-05 00:02:02,977[0m] {[34mscheduler_job.py:[0m1221} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-10-05 00:02:31,580[0m] {[34mscheduler_job.py:[0m756} ERROR[0m - Exception when executing SchedulerJob._run_scheduler_loop[0m
Traceback (most recent call last):
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1705, in _execute_context
    self.dialect.do_execute(
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 716, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: dag

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kennedy/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job.py", line 739, in _execute
    self._run_scheduler_loop()
  File "/home/kennedy/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job.py", line 827, in _run_scheduler_loop
    num_queued_tis = self._do_scheduling(session)
  File "/home/kennedy/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job.py", line 899, in _do_scheduling
    self._create_dagruns_for_dags(guard, session)
  File "/home/kennedy/.local/lib/python3.10/site-packages/airflow/utils/retries.py", line 76, in wrapped_function
    for attempt in run_with_db_retries(max_retries=retries, logger=logger, **retry_kwargs):
  File "/home/kennedy/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/kennedy/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 360, in iter
    raise retry_exc.reraise()
  File "/home/kennedy/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 193, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/kennedy/.local/lib/python3.10/site-packages/airflow/utils/retries.py", line 85, in wrapped_function
    return func(*args, **kwargs)
  File "/home/kennedy/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job.py", line 967, in _create_dagruns_for_dags
    self._create_dag_runs(query.all(), session)
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2683, in all
    return self._iter().all()
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2818, in _iter
    result = self.session.execute(
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1670, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 313, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1389, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1748, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1929, in _handle_dbapi_exception
    util.raise_(
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1705, in _execute_context
    self.dialect.do_execute(
  File "/home/kennedy/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 716, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: dag
[SQL: SELECT dag.dag_id AS dag_dag_id, dag.root_dag_id AS dag_root_dag_id, dag.is_paused AS dag_is_paused, dag.is_subdag AS dag_is_subdag, dag.is_active AS dag_is_active, dag.last_parsed_time AS dag_last_parsed_time, dag.last_pickled AS dag_last_pickled, dag.last_expired AS dag_last_expired, dag.scheduler_lock AS dag_scheduler_lock, dag.pickle_id AS dag_pickle_id, dag.fileloc AS dag_fileloc, dag.owners AS dag_owners, dag.description AS dag_description, dag.default_view AS dag_default_view, dag.schedule_interval AS dag_schedule_interval, dag.timetable_description AS dag_timetable_description, dag.max_active_tasks AS dag_max_active_tasks, dag.max_active_runs AS dag_max_active_runs, dag.has_task_concurrency_limits AS dag_has_task_concurrency_limits, dag.has_import_errors AS dag_has_import_errors, dag.next_dagrun AS dag_next_dagrun, dag.next_dagrun_data_interval_start AS dag_next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end AS dag_next_dagrun_data_interval_end, dag.next_dagrun_create_after AS dag_next_dagrun_create_after 
FROM dag 
WHERE dag.is_paused = 0 AND dag.is_active = 1 AND dag.has_import_errors = 0 AND dag.next_dagrun_create_after <= CURRENT_TIMESTAMP ORDER BY dag.next_dagrun_create_after
 LIMIT ? OFFSET ?]
[parameters: (10, 0)]
(Background on this error at: http://sqlalche.me/e/14/e3q8)[0m
[[34m2024-10-05 00:02:32,622[0m] {[34mprocess_utils.py:[0m125} INFO[0m - Sending Signals.SIGTERM to group 96123. PIDs of all processes in the group: [96123][0m
[[34m2024-10-05 00:02:32,622[0m] {[34mprocess_utils.py:[0m80} INFO[0m - Sending the signal Signals.SIGTERM to group 96123[0m
[[34m2024-10-05 00:02:32,956[0m] {[34mprocess_utils.py:[0m75} INFO[0m - Process psutil.Process(pid=96123, status='terminated', exitcode=0, started='23:31:55') (96123) terminated with exit code 0[0m
[[34m2024-10-05 00:02:32,957[0m] {[34mscheduler_job.py:[0m768} INFO[0m - Exited execute loop[0m
